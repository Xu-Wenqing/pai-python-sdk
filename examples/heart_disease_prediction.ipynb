{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pycharm-cbc784f4",
   "language": "python",
   "display_name": "PyCharm (pypai)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction Demo\n",
    "\n",
    "- 这个样例是PAI Studio版本的[心脏病预测案例](https://help.aliyun.com/document_detail/34929.html?spm=a2c4g.11186623.6.769.5b7e340fwAhTsW)的PAIFlow版本，使用了PAIFlow Pipeline service运行心脏病预测案例中的workflow。\n",
    "\n",
    "- 本样例与PAI Studio版本稍有不同，目前的PAIFlow没有提供混淆矩阵的组件，对于结果的评估使用二分类评估器。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化运行环境\n",
    "\n",
    "- 需要提供阿里云的访问密钥对初始化Session:\n",
    "    - https://yuque.antfin-inc.com/pai-user/manual/fqcsry\n",
    "    - 需要使用*set_default_pai_session*(必需)函数，传入AK, 默认的oss_bucket(可选）, 默认的odps_client（可选)初始化默认的session.\n",
    "- 目前的算法模块主要依赖于XFlow实现，数据集和结果数据集大多数情况下是存储在MaxCompute中，因而需要使用MaxCompute访问(ODPS)\n",
    "- 该案例中，PAI算法服务需要访问用户的OSS，提供相应的oss bucket, endpoint, path(存储PMML模型路径), rolearn(PAI服务访问用户OSS的凭证)\n",
    "    - oss rolearn参考 https://help.aliyun.com/document_detail/106225.html?spm=a2c6h.12873639.0.0.82bd6a8a6K624y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import pai\n",
    "print(pai.__file__)\n",
    "\n",
    "import yaml\n",
    "\n",
    "from pai.core import setup_default_pai_session, Workspace\n",
    "from pai.common import ProviderAlibabaPAI\n",
    "from pai.pipeline import Pipeline\n",
    "from pai.pipeline.template import PipelineTemplate\n",
    "from pai.utils import gen_temp_table\n",
    "from pai.pipeline.types import  PipelineParameter, PipelineArtifact, ArtifactMetadata\n",
    "from pai.pipeline.step import PipelineStep\n",
    "\n",
    "from odps import ODPS, DataFrame\n",
    "import oss2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "##################################### User Config field ##############################\n",
    "config = {\n",
    "    \"access_key_id\": \"your_access_key\",\n",
    "    \"access_key_secret\": \"your_access_key_secret\",\n",
    "    \"region_id\": \"your_region\",\n",
    "    }\n",
    "\n",
    "default_project = \"default_odps_project_name\"\n",
    "\n",
    "\n",
    "oss_endpoint = \"your_oss_endpoint\"\n",
    "# oss_path = \"/paiflow/model_transfer2oss_test/\"\n",
    "oss_path = \"/model_store_path_in_oss/\"\n",
    "oss_bucket_name = \"your_oss_bucket_name\"\n",
    "# OSS Rolearn\n",
    "# 公有云用户参考: https://help.aliyun.com/document_detail/106225.html?spm=a2c6h.12873639.0.0.82bd6a8a6K624y\n",
    "# 集团内参考: https://yuque.antfin-inc.com/pai-user/manual/fqcsry\n",
    "# oss_rolearn = \"acs:ram::{{your_account_id}}:role/aliyunodpspaidefaultrole\"\n",
    "oss_rolearn = \"your_oss_rolearn\"\n",
    "\n",
    "\n",
    "xflow_execution = {\n",
    "    \"odpsInfoFile\": \"/share/base/odpsInfo.ini\",\n",
    "    \"endpoint\": \"ODPS_Endpoint\",\n",
    "    \"logViewHost\": \"logview_host_config\",\n",
    "    \"odpsProject\": default_project,\n",
    "}\n",
    "\n",
    "################################### User Config field ##############################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "##################################### User Config field ##############################\n",
    "config = {\n",
    "         \"access_key_id\": \"AccessKeyId\",\n",
    "         \"access_key_secret\": \"AccessKeySecret\",\n",
    "         \"region_id\": \"center\",\n",
    "         }\n",
    "\n",
    "workspace_name = \"test_workspace\"\n",
    "\n",
    "\n",
    "oss_endpoint = \"cn-shanghai.oss.aliyuncs.com\"\n",
    "oss_path = \"/model_store_path_in_oss/\"\n",
    "oss_bucket_name = \"pai-sdk-test\"\n",
    "\n",
    "# OSS Rolearn\n",
    "# 公有云用户参考: https://help.aliyun.com/document_detail/106225.html?spm=a2c6h.12873639.0.0.82bd6a8a6K624y\n",
    "# 集团内参考: https://yuque.antfin-inc.com/pai-user/manual/fqcsry\n",
    "# oss_rolearn = \"acs:ram::{{your_account_id}}:role/aliyunodpspaidefaultrole\"\n",
    "oss_rolearn = \"acs:ram::1557702098194904:role/lq-test-20200902\"\n",
    "\n",
    "\n",
    "default_project = \"pai_dev\"\n",
    "xflow_execution = {\n",
    "                  \"odpsInfoFile\": \"/share/base/odpsInfo.ini\",\n",
    "                  \"endpoint\": \"http://service-corp.odps.aliyun-inc.com/api\",\n",
    "                  \"logViewHost\": \"http://logview.alibaba-inc.com\",\n",
    "                  \"odpsProject\": default_project,\n",
    "}\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "odps_client = ODPS(access_id=config[\"access_key_id\"], secret_access_key=config[\"access_key_secret\"], project=default_project, endpoint=xflow_execution[\"endpoint\"])\n",
    "oss_auth = oss2.Auth(access_key_id=config[\"access_key_id\"], access_key_secret=config[\"access_key_secret\"])\n",
    "oss_bucket = oss2.Bucket(auth=oss_auth, endpoint=oss_endpoint, bucket_name=oss_bucket_name)\n",
    "\n",
    "session = setup_default_pai_session(oss_bucket=oss_bucket, **config)\n",
    "\n",
    "workspace = Workspace.get_by_name(workspace_name)\n",
    "if not workspace:\n",
    "    workspace = Workspace.create(name=workspace_name)\n",
    "\n",
    "print(workspace)\n",
    "session.set_workspace(workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 获取可用的PipelineTemplate\n",
    "\n",
    "PipelineTemplate表示Pipeline或是Component的*定义*， 可以是保存在服务端的模板， 也可以是由本地构造/拼接获得的组件的定义，区别是前者包含一个由服务端生成的PipelineId标识，后者可以通过save接口保存到服务端，并且获得对应的PipelineId。\n",
    "\n",
    "### PipelineTemplate class可以通过:\n",
    "\n",
    "- list_templates(identifier, provider, version, fuzzy):\n",
    "    - 搜索/列出获得已保存的PAIFlow.\n",
    "\n",
    "- get(pipeline_id)/get_by_identifier(identifier, provider, version):\n",
    "    - 获得具体的某一个Pipeline模板\n",
    "\n",
    "\n",
    "### PipelineTemplate对象主要支持：\n",
    "\n",
    "- load():\n",
    "    - 尝试获得Template的实现（调用DescribePipeline接口获得详细的Implementation），解析实现获得对应的Component或是Pipeline对象.\n",
    "\n",
    "- run(job_name, arguments):\n",
    "    - 传入运行参数直接运行任务\n",
    "\n",
    "- inputs/outputs:\n",
    "    - property: 获取查看模板的inputs/outputs信息\n",
    "\n",
    "- save(identifier, version):\n",
    "    - 指定identifier和version，保存当前的Manifest\n",
    "\n",
    "- as_step(inputs, name)：\n",
    "    - 生成一个PipelineStep,可以用于Pipeline拼接\n",
    "    - 注：目前PAIFlow的后端只支持使用*已保存*template\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = next(PipelineTemplate.list(identifier=\"xflow\", provider=ProviderAlibabaPAI, fuzzy=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "PipelineTemplate: {PipelineId:pipeline-1knlv5f04x05p51str, Identifier:type-transform-xflow-maxCompute, Provider:pai, Version:v1}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "InputsSpec:\n\tPipelineParameter:{Name:execution, Kind:inputs, Required:True, Value:None, Desc:必选，执行环境}\n\tPipelineParameter:{Name:outputTable, Kind:inputs, Required:True, Value:None, Desc:None}\n\tPipelineParameter:{Name:reserveOldFeat, Kind:inputs, Required:False, Value:False, Desc:是否保持原来变换前的数据列}\n\tPipelineParameter:{Name:cols_to_double, Kind:inputs, Required:False, Value:, Desc:需要类型转换到double的特征列}\n\tPipelineParameter:{Name:cols_to_string, Kind:inputs, Required:False, Value:, Desc:需要类型转换到string的特征列}\n\tPipelineParameter:{Name:cols_to_int, Kind:inputs, Required:False, Value:, Desc:需要类型转换到int的特征列}\n\tPipelineParameter:{Name:default_int_value, Kind:inputs, Required:False, Value:0, Desc:当特征字段为空时的值}\n\tPipelineParameter:{Name:default_double_value, Kind:inputs, Required:False, Value:0.0, Desc:当特征字段为空时的值}\n\tPipelineParameter:{Name:default_string_value, Kind:inputs, Required:False, Value:, Desc:当特征字段为空时的值}\n\tPipelineParameter:{Name:coreNum, Kind:inputs, Required:False, Value:, Desc:节点个数}\n\tPipelineParameter:{Name:memSizePerCore, Kind:inputs, Required:False, Value:, Desc:单个结点内存大小，单位M}\n\tPipelineParameter:{Name:lifecycle, Kind:inputs, Required:False, Value:28, Desc:可选，outputTable结果表生命周期}\n\tPipelineArtifact:{Name:inputArtifact, Kind:inputs, Required:True, Value:None, Desc:可选，切分至输出表1的数据比例}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-By-Step的方式运行任务\n",
    "\n",
    "- 使用同步方式，提交任务，获得返回结果后，使用结果数据集提交给下一个任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用的数据集\n",
    "数据集使用的是PAI提供的公共读MaxCompute table- heart_disease_prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0f366bb37540cbb32ae975d7b5cad7",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "TransientProgressBar(value=0.0)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e475b3d07ebe4c7eaf612f3efe124d18",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "InstancesProgress()"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec8bff3ed794ed6ac9174a25345e9d0",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HTMLNotifier()"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe7336119ad4a47badeb0d5110a63bd",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "DFViewWidget()"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slop</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>status</th>\n      <th>style</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63.0</td>\n      <td>male</td>\n      <td>angina</td>\n      <td>145.0</td>\n      <td>233.0</td>\n      <td>true</td>\n      <td>hyp</td>\n      <td>150.0</td>\n      <td>fal</td>\n      <td>2.3</td>\n      <td>down</td>\n      <td>0.0</td>\n      <td>fix</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67.0</td>\n      <td>male</td>\n      <td>asympt</td>\n      <td>160.0</td>\n      <td>286.0</td>\n      <td>fal</td>\n      <td>hyp</td>\n      <td>108.0</td>\n      <td>true</td>\n      <td>1.5</td>\n      <td>flat</td>\n      <td>3.0</td>\n      <td>norm</td>\n      <td>sick</td>\n      <td>S2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67.0</td>\n      <td>male</td>\n      <td>asympt</td>\n      <td>120.0</td>\n      <td>229.0</td>\n      <td>fal</td>\n      <td>hyp</td>\n      <td>129.0</td>\n      <td>true</td>\n      <td>2.6</td>\n      <td>flat</td>\n      <td>2.0</td>\n      <td>rev</td>\n      <td>sick</td>\n      <td>S1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37.0</td>\n      <td>male</td>\n      <td>notang</td>\n      <td>130.0</td>\n      <td>250.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>187.0</td>\n      <td>fal</td>\n      <td>3.5</td>\n      <td>down</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41.0</td>\n      <td>fem</td>\n      <td>abnang</td>\n      <td>130.0</td>\n      <td>204.0</td>\n      <td>fal</td>\n      <td>hyp</td>\n      <td>172.0</td>\n      <td>fal</td>\n      <td>1.4</td>\n      <td>up</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>56.0</td>\n      <td>male</td>\n      <td>abnang</td>\n      <td>120.0</td>\n      <td>236.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>178.0</td>\n      <td>fal</td>\n      <td>0.8</td>\n      <td>up</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>62.0</td>\n      <td>fem</td>\n      <td>asympt</td>\n      <td>140.0</td>\n      <td>268.0</td>\n      <td>fal</td>\n      <td>hyp</td>\n      <td>160.0</td>\n      <td>fal</td>\n      <td>3.6</td>\n      <td>down</td>\n      <td>2.0</td>\n      <td>norm</td>\n      <td>sick</td>\n      <td>S3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>57.0</td>\n      <td>fem</td>\n      <td>asympt</td>\n      <td>120.0</td>\n      <td>354.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>163.0</td>\n      <td>true</td>\n      <td>0.6</td>\n      <td>up</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>63.0</td>\n      <td>male</td>\n      <td>asympt</td>\n      <td>130.0</td>\n      <td>254.0</td>\n      <td>fal</td>\n      <td>hyp</td>\n      <td>147.0</td>\n      <td>fal</td>\n      <td>1.4</td>\n      <td>flat</td>\n      <td>1.0</td>\n      <td>rev</td>\n      <td>sick</td>\n      <td>S2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>53.0</td>\n      <td>male</td>\n      <td>asympt</td>\n      <td>140.0</td>\n      <td>203.0</td>\n      <td>true</td>\n      <td>hyp</td>\n      <td>155.0</td>\n      <td>true</td>\n      <td>3.1</td>\n      <td>down</td>\n      <td>0.0</td>\n      <td>rev</td>\n      <td>sick</td>\n      <td>S1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>57.0</td>\n      <td>male</td>\n      <td>asympt</td>\n      <td>140.0</td>\n      <td>192.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>148.0</td>\n      <td>fal</td>\n      <td>0.4</td>\n      <td>flat</td>\n      <td>0.0</td>\n      <td>fix</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>56.0</td>\n      <td>fem</td>\n      <td>abnang</td>\n      <td>140.0</td>\n      <td>294.0</td>\n      <td>fal</td>\n      <td>hyp</td>\n      <td>153.0</td>\n      <td>fal</td>\n      <td>1.3</td>\n      <td>flat</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>56.0</td>\n      <td>male</td>\n      <td>notang</td>\n      <td>130.0</td>\n      <td>256.0</td>\n      <td>true</td>\n      <td>hyp</td>\n      <td>142.0</td>\n      <td>true</td>\n      <td>0.6</td>\n      <td>flat</td>\n      <td>1.0</td>\n      <td>fix</td>\n      <td>sick</td>\n      <td>S2</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>44.0</td>\n      <td>male</td>\n      <td>abnang</td>\n      <td>120.0</td>\n      <td>263.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>173.0</td>\n      <td>fal</td>\n      <td>0.0</td>\n      <td>up</td>\n      <td>0.0</td>\n      <td>rev</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>49.0</td>\n      <td>male</td>\n      <td>abnang</td>\n      <td>130.0</td>\n      <td>266.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>171.0</td>\n      <td>fal</td>\n      <td>0.6</td>\n      <td>up</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>64.0</td>\n      <td>male</td>\n      <td>angina</td>\n      <td>110.0</td>\n      <td>211.0</td>\n      <td>fal</td>\n      <td>hyp</td>\n      <td>144.0</td>\n      <td>true</td>\n      <td>1.8</td>\n      <td>flat</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>58.0</td>\n      <td>fem</td>\n      <td>angina</td>\n      <td>150.0</td>\n      <td>283.0</td>\n      <td>true</td>\n      <td>hyp</td>\n      <td>162.0</td>\n      <td>fal</td>\n      <td>1.0</td>\n      <td>up</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>58.0</td>\n      <td>male</td>\n      <td>abnang</td>\n      <td>120.0</td>\n      <td>284.0</td>\n      <td>fal</td>\n      <td>hyp</td>\n      <td>160.0</td>\n      <td>fal</td>\n      <td>1.8</td>\n      <td>flat</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>sick</td>\n      <td>S1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>58.0</td>\n      <td>male</td>\n      <td>notang</td>\n      <td>132.0</td>\n      <td>224.0</td>\n      <td>fal</td>\n      <td>hyp</td>\n      <td>173.0</td>\n      <td>fal</td>\n      <td>3.2</td>\n      <td>up</td>\n      <td>2.0</td>\n      <td>rev</td>\n      <td>sick</td>\n      <td>S3</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>60.0</td>\n      <td>male</td>\n      <td>asympt</td>\n      <td>130.0</td>\n      <td>206.0</td>\n      <td>fal</td>\n      <td>hyp</td>\n      <td>132.0</td>\n      <td>true</td>\n      <td>2.4</td>\n      <td>flat</td>\n      <td>2.0</td>\n      <td>rev</td>\n      <td>sick</td>\n      <td>S4</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>50.0</td>\n      <td>fem</td>\n      <td>notang</td>\n      <td>120.0</td>\n      <td>219.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>158.0</td>\n      <td>fal</td>\n      <td>1.6</td>\n      <td>flat</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>58.0</td>\n      <td>fem</td>\n      <td>notang</td>\n      <td>120.0</td>\n      <td>340.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>172.0</td>\n      <td>fal</td>\n      <td>0.0</td>\n      <td>up</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>66.0</td>\n      <td>fem</td>\n      <td>angina</td>\n      <td>150.0</td>\n      <td>226.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>114.0</td>\n      <td>fal</td>\n      <td>2.6</td>\n      <td>down</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>43.0</td>\n      <td>male</td>\n      <td>asympt</td>\n      <td>150.0</td>\n      <td>247.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>171.0</td>\n      <td>fal</td>\n      <td>1.5</td>\n      <td>up</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>40.0</td>\n      <td>male</td>\n      <td>asympt</td>\n      <td>110.0</td>\n      <td>167.0</td>\n      <td>fal</td>\n      <td>hyp</td>\n      <td>114.0</td>\n      <td>true</td>\n      <td>2.0</td>\n      <td>flat</td>\n      <td>0.0</td>\n      <td>rev</td>\n      <td>sick</td>\n      <td>S3</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>69.0</td>\n      <td>fem</td>\n      <td>angina</td>\n      <td>140.0</td>\n      <td>239.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>151.0</td>\n      <td>fal</td>\n      <td>1.8</td>\n      <td>up</td>\n      <td>2.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>60.0</td>\n      <td>male</td>\n      <td>asympt</td>\n      <td>117.0</td>\n      <td>230.0</td>\n      <td>true</td>\n      <td>norm</td>\n      <td>160.0</td>\n      <td>true</td>\n      <td>1.4</td>\n      <td>up</td>\n      <td>2.0</td>\n      <td>rev</td>\n      <td>sick</td>\n      <td>S2</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>64.0</td>\n      <td>male</td>\n      <td>notang</td>\n      <td>140.0</td>\n      <td>335.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>158.0</td>\n      <td>fal</td>\n      <td>0.0</td>\n      <td>up</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>sick</td>\n      <td>S1</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>59.0</td>\n      <td>male</td>\n      <td>asympt</td>\n      <td>135.0</td>\n      <td>234.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>161.0</td>\n      <td>fal</td>\n      <td>0.5</td>\n      <td>flat</td>\n      <td>0.0</td>\n      <td>rev</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>44.0</td>\n      <td>male</td>\n      <td>notang</td>\n      <td>130.0</td>\n      <td>233.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>179.0</td>\n      <td>true</td>\n      <td>0.4</td>\n      <td>up</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>273</th>\n      <td>57.0</td>\n      <td>fem</td>\n      <td>asympt</td>\n      <td>128.0</td>\n      <td>303.0</td>\n      <td>fal</td>\n      <td>hyp</td>\n      <td>159.0</td>\n      <td>fal</td>\n      <td>0.0</td>\n      <td>up</td>\n      <td>1.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>274</th>\n      <td>71.0</td>\n      <td>fem</td>\n      <td>notang</td>\n      <td>110.0</td>\n      <td>265.0</td>\n      <td>true</td>\n      <td>hyp</td>\n      <td>130.0</td>\n      <td>fal</td>\n      <td>0.0</td>\n      <td>up</td>\n      <td>1.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>275</th>\n      <td>49.0</td>\n      <td>male</td>\n      <td>notang</td>\n      <td>120.0</td>\n      <td>188.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>139.0</td>\n      <td>fal</td>\n      <td>2.0</td>\n      <td>flat</td>\n      <td>3.0</td>\n      <td>rev</td>\n      <td>sick</td>\n      <td>S3</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>54.0</td>\n      <td>male</td>\n      <td>abnang</td>\n      <td>108.0</td>\n      <td>309.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>156.0</td>\n      <td>fal</td>\n      <td>0.0</td>\n      <td>up</td>\n      <td>0.0</td>\n      <td>rev</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>277</th>\n      <td>59.0</td>\n      <td>male</td>\n      <td>asympt</td>\n      <td>140.0</td>\n      <td>177.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>162.0</td>\n      <td>true</td>\n      <td>0.0</td>\n      <td>up</td>\n      <td>1.0</td>\n      <td>rev</td>\n      <td>sick</td>\n      <td>S2</td>\n    </tr>\n    <tr>\n      <th>278</th>\n      <td>57.0</td>\n      <td>male</td>\n      <td>notang</td>\n      <td>128.0</td>\n      <td>229.0</td>\n      <td>fal</td>\n      <td>hyp</td>\n      <td>150.0</td>\n      <td>fal</td>\n      <td>0.4</td>\n      <td>flat</td>\n      <td>1.0</td>\n      <td>rev</td>\n      <td>sick</td>\n      <td>S1</td>\n    </tr>\n    <tr>\n      <th>279</th>\n      <td>65.0</td>\n      <td>male</td>\n      <td>angina</td>\n      <td>138.0</td>\n      <td>282.0</td>\n      <td>true</td>\n      <td>hyp</td>\n      <td>174.0</td>\n      <td>fal</td>\n      <td>1.4</td>\n      <td>flat</td>\n      <td>1.0</td>\n      <td>norm</td>\n      <td>sick</td>\n      <td>S1</td>\n    </tr>\n    <tr>\n      <th>280</th>\n      <td>45.0</td>\n      <td>fem</td>\n      <td>abnang</td>\n      <td>130.0</td>\n      <td>234.0</td>\n      <td>fal</td>\n      <td>hyp</td>\n      <td>175.0</td>\n      <td>fal</td>\n      <td>0.6</td>\n      <td>flat</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>281</th>\n      <td>56.0</td>\n      <td>fem</td>\n      <td>asympt</td>\n      <td>200.0</td>\n      <td>288.0</td>\n      <td>true</td>\n      <td>hyp</td>\n      <td>133.0</td>\n      <td>true</td>\n      <td>4.0</td>\n      <td>down</td>\n      <td>2.0</td>\n      <td>rev</td>\n      <td>sick</td>\n      <td>S3</td>\n    </tr>\n    <tr>\n      <th>282</th>\n      <td>54.0</td>\n      <td>male</td>\n      <td>asympt</td>\n      <td>110.0</td>\n      <td>239.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>126.0</td>\n      <td>true</td>\n      <td>2.8</td>\n      <td>flat</td>\n      <td>1.0</td>\n      <td>rev</td>\n      <td>sick</td>\n      <td>S3</td>\n    </tr>\n    <tr>\n      <th>283</th>\n      <td>44.0</td>\n      <td>male</td>\n      <td>abnang</td>\n      <td>120.0</td>\n      <td>220.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>170.0</td>\n      <td>fal</td>\n      <td>0.0</td>\n      <td>up</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>284</th>\n      <td>62.0</td>\n      <td>fem</td>\n      <td>asympt</td>\n      <td>124.0</td>\n      <td>209.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>163.0</td>\n      <td>fal</td>\n      <td>0.0</td>\n      <td>up</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>285</th>\n      <td>54.0</td>\n      <td>male</td>\n      <td>notang</td>\n      <td>120.0</td>\n      <td>258.0</td>\n      <td>fal</td>\n      <td>hyp</td>\n      <td>147.0</td>\n      <td>fal</td>\n      <td>0.4</td>\n      <td>flat</td>\n      <td>0.0</td>\n      <td>rev</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>286</th>\n      <td>51.0</td>\n      <td>male</td>\n      <td>notang</td>\n      <td>94.0</td>\n      <td>227.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>154.0</td>\n      <td>true</td>\n      <td>0.0</td>\n      <td>up</td>\n      <td>1.0</td>\n      <td>rev</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>287</th>\n      <td>44.0</td>\n      <td>fem</td>\n      <td>notang</td>\n      <td>118.0</td>\n      <td>242.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>149.0</td>\n      <td>fal</td>\n      <td>0.3</td>\n      <td>flat</td>\n      <td>1.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>288</th>\n      <td>58.0</td>\n      <td>fem</td>\n      <td>abnang</td>\n      <td>136.0</td>\n      <td>319.0</td>\n      <td>true</td>\n      <td>hyp</td>\n      <td>152.0</td>\n      <td>fal</td>\n      <td>0.0</td>\n      <td>up</td>\n      <td>2.0</td>\n      <td>norm</td>\n      <td>sick</td>\n      <td>S3</td>\n    </tr>\n    <tr>\n      <th>289</th>\n      <td>60.0</td>\n      <td>fem</td>\n      <td>angina</td>\n      <td>150.0</td>\n      <td>240.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>171.0</td>\n      <td>fal</td>\n      <td>0.9</td>\n      <td>up</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>290</th>\n      <td>44.0</td>\n      <td>male</td>\n      <td>notang</td>\n      <td>120.0</td>\n      <td>226.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>169.0</td>\n      <td>fal</td>\n      <td>0.0</td>\n      <td>up</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>291</th>\n      <td>61.0</td>\n      <td>male</td>\n      <td>asympt</td>\n      <td>138.0</td>\n      <td>166.0</td>\n      <td>fal</td>\n      <td>hyp</td>\n      <td>125.0</td>\n      <td>true</td>\n      <td>3.6</td>\n      <td>flat</td>\n      <td>1.0</td>\n      <td>norm</td>\n      <td>sick</td>\n      <td>S4</td>\n    </tr>\n    <tr>\n      <th>292</th>\n      <td>42.0</td>\n      <td>male</td>\n      <td>asympt</td>\n      <td>136.0</td>\n      <td>315.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>125.0</td>\n      <td>true</td>\n      <td>1.8</td>\n      <td>flat</td>\n      <td>0.0</td>\n      <td>fix</td>\n      <td>sick</td>\n      <td>S2</td>\n    </tr>\n    <tr>\n      <th>293</th>\n      <td>68.0</td>\n      <td>male</td>\n      <td>notang</td>\n      <td>118.0</td>\n      <td>277.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>151.0</td>\n      <td>fal</td>\n      <td>1.0</td>\n      <td>up</td>\n      <td>1.0</td>\n      <td>rev</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>294</th>\n      <td>46.0</td>\n      <td>male</td>\n      <td>abnang</td>\n      <td>101.0</td>\n      <td>197.0</td>\n      <td>true</td>\n      <td>norm</td>\n      <td>156.0</td>\n      <td>fal</td>\n      <td>0.0</td>\n      <td>up</td>\n      <td>0.0</td>\n      <td>rev</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>77.0</td>\n      <td>male</td>\n      <td>asympt</td>\n      <td>125.0</td>\n      <td>304.0</td>\n      <td>fal</td>\n      <td>hyp</td>\n      <td>162.0</td>\n      <td>true</td>\n      <td>0.0</td>\n      <td>up</td>\n      <td>3.0</td>\n      <td>norm</td>\n      <td>sick</td>\n      <td>S4</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>54.0</td>\n      <td>fem</td>\n      <td>notang</td>\n      <td>110.0</td>\n      <td>214.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>158.0</td>\n      <td>fal</td>\n      <td>1.6</td>\n      <td>flat</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>58.0</td>\n      <td>fem</td>\n      <td>asympt</td>\n      <td>100.0</td>\n      <td>248.0</td>\n      <td>fal</td>\n      <td>hyp</td>\n      <td>122.0</td>\n      <td>fal</td>\n      <td>1.0</td>\n      <td>flat</td>\n      <td>0.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>48.0</td>\n      <td>male</td>\n      <td>notang</td>\n      <td>124.0</td>\n      <td>255.0</td>\n      <td>true</td>\n      <td>norm</td>\n      <td>175.0</td>\n      <td>fal</td>\n      <td>0.0</td>\n      <td>up</td>\n      <td>2.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>57.0</td>\n      <td>male</td>\n      <td>asympt</td>\n      <td>132.0</td>\n      <td>207.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>168.0</td>\n      <td>true</td>\n      <td>0.0</td>\n      <td>up</td>\n      <td>0.0</td>\n      <td>rev</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>49.0</td>\n      <td>male</td>\n      <td>notang</td>\n      <td>118.0</td>\n      <td>149.0</td>\n      <td>fal</td>\n      <td>hyp</td>\n      <td>126.0</td>\n      <td>fal</td>\n      <td>0.8</td>\n      <td>up</td>\n      <td>3.0</td>\n      <td>norm</td>\n      <td>sick</td>\n      <td>S1</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>74.0</td>\n      <td>fem</td>\n      <td>abnang</td>\n      <td>120.0</td>\n      <td>269.0</td>\n      <td>fal</td>\n      <td>hyp</td>\n      <td>121.0</td>\n      <td>true</td>\n      <td>0.2</td>\n      <td>up</td>\n      <td>1.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>54.0</td>\n      <td>fem</td>\n      <td>notang</td>\n      <td>160.0</td>\n      <td>201.0</td>\n      <td>fal</td>\n      <td>norm</td>\n      <td>163.0</td>\n      <td>fal</td>\n      <td>0.0</td>\n      <td>up</td>\n      <td>1.0</td>\n      <td>norm</td>\n      <td>buff</td>\n      <td>H</td>\n    </tr>\n  </tbody>\n</table>\n<p>303 rows × 15 columns</p>\n</div>",
      "text/plain": "      age   sex      cp trestbps   chol   fbs restecg thalach exang oldpeak  \\\n0    63.0  male  angina    145.0  233.0  true     hyp   150.0   fal     2.3   \n1    67.0  male  asympt    160.0  286.0   fal     hyp   108.0  true     1.5   \n2    67.0  male  asympt    120.0  229.0   fal     hyp   129.0  true     2.6   \n3    37.0  male  notang    130.0  250.0   fal    norm   187.0   fal     3.5   \n4    41.0   fem  abnang    130.0  204.0   fal     hyp   172.0   fal     1.4   \n5    56.0  male  abnang    120.0  236.0   fal    norm   178.0   fal     0.8   \n6    62.0   fem  asympt    140.0  268.0   fal     hyp   160.0   fal     3.6   \n7    57.0   fem  asympt    120.0  354.0   fal    norm   163.0  true     0.6   \n8    63.0  male  asympt    130.0  254.0   fal     hyp   147.0   fal     1.4   \n9    53.0  male  asympt    140.0  203.0  true     hyp   155.0  true     3.1   \n10   57.0  male  asympt    140.0  192.0   fal    norm   148.0   fal     0.4   \n11   56.0   fem  abnang    140.0  294.0   fal     hyp   153.0   fal     1.3   \n12   56.0  male  notang    130.0  256.0  true     hyp   142.0  true     0.6   \n13   44.0  male  abnang    120.0  263.0   fal    norm   173.0   fal     0.0   \n14   49.0  male  abnang    130.0  266.0   fal    norm   171.0   fal     0.6   \n15   64.0  male  angina    110.0  211.0   fal     hyp   144.0  true     1.8   \n16   58.0   fem  angina    150.0  283.0  true     hyp   162.0   fal     1.0   \n17   58.0  male  abnang    120.0  284.0   fal     hyp   160.0   fal     1.8   \n18   58.0  male  notang    132.0  224.0   fal     hyp   173.0   fal     3.2   \n19   60.0  male  asympt    130.0  206.0   fal     hyp   132.0  true     2.4   \n20   50.0   fem  notang    120.0  219.0   fal    norm   158.0   fal     1.6   \n21   58.0   fem  notang    120.0  340.0   fal    norm   172.0   fal     0.0   \n22   66.0   fem  angina    150.0  226.0   fal    norm   114.0   fal     2.6   \n23   43.0  male  asympt    150.0  247.0   fal    norm   171.0   fal     1.5   \n24   40.0  male  asympt    110.0  167.0   fal     hyp   114.0  true     2.0   \n25   69.0   fem  angina    140.0  239.0   fal    norm   151.0   fal     1.8   \n26   60.0  male  asympt    117.0  230.0  true    norm   160.0  true     1.4   \n27   64.0  male  notang    140.0  335.0   fal    norm   158.0   fal     0.0   \n28   59.0  male  asympt    135.0  234.0   fal    norm   161.0   fal     0.5   \n29   44.0  male  notang    130.0  233.0   fal    norm   179.0  true     0.4   \n..    ...   ...     ...      ...    ...   ...     ...     ...   ...     ...   \n273  57.0   fem  asympt    128.0  303.0   fal     hyp   159.0   fal     0.0   \n274  71.0   fem  notang    110.0  265.0  true     hyp   130.0   fal     0.0   \n275  49.0  male  notang    120.0  188.0   fal    norm   139.0   fal     2.0   \n276  54.0  male  abnang    108.0  309.0   fal    norm   156.0   fal     0.0   \n277  59.0  male  asympt    140.0  177.0   fal    norm   162.0  true     0.0   \n278  57.0  male  notang    128.0  229.0   fal     hyp   150.0   fal     0.4   \n279  65.0  male  angina    138.0  282.0  true     hyp   174.0   fal     1.4   \n280  45.0   fem  abnang    130.0  234.0   fal     hyp   175.0   fal     0.6   \n281  56.0   fem  asympt    200.0  288.0  true     hyp   133.0  true     4.0   \n282  54.0  male  asympt    110.0  239.0   fal    norm   126.0  true     2.8   \n283  44.0  male  abnang    120.0  220.0   fal    norm   170.0   fal     0.0   \n284  62.0   fem  asympt    124.0  209.0   fal    norm   163.0   fal     0.0   \n285  54.0  male  notang    120.0  258.0   fal     hyp   147.0   fal     0.4   \n286  51.0  male  notang     94.0  227.0   fal    norm   154.0  true     0.0   \n287  44.0   fem  notang    118.0  242.0   fal    norm   149.0   fal     0.3   \n288  58.0   fem  abnang    136.0  319.0  true     hyp   152.0   fal     0.0   \n289  60.0   fem  angina    150.0  240.0   fal    norm   171.0   fal     0.9   \n290  44.0  male  notang    120.0  226.0   fal    norm   169.0   fal     0.0   \n291  61.0  male  asympt    138.0  166.0   fal     hyp   125.0  true     3.6   \n292  42.0  male  asympt    136.0  315.0   fal    norm   125.0  true     1.8   \n293  68.0  male  notang    118.0  277.0   fal    norm   151.0   fal     1.0   \n294  46.0  male  abnang    101.0  197.0  true    norm   156.0   fal     0.0   \n295  77.0  male  asympt    125.0  304.0   fal     hyp   162.0  true     0.0   \n296  54.0   fem  notang    110.0  214.0   fal    norm   158.0   fal     1.6   \n297  58.0   fem  asympt    100.0  248.0   fal     hyp   122.0   fal     1.0   \n298  48.0  male  notang    124.0  255.0  true    norm   175.0   fal     0.0   \n299  57.0  male  asympt    132.0  207.0   fal    norm   168.0  true     0.0   \n300  49.0  male  notang    118.0  149.0   fal     hyp   126.0   fal     0.8   \n301  74.0   fem  abnang    120.0  269.0   fal     hyp   121.0  true     0.2   \n302  54.0   fem  notang    160.0  201.0   fal    norm   163.0   fal     0.0   \n\n     slop   ca  thal status style  \n0    down  0.0   fix   buff     H  \n1    flat  3.0  norm   sick    S2  \n2    flat  2.0   rev   sick    S1  \n3    down  0.0  norm   buff     H  \n4      up  0.0  norm   buff     H  \n5      up  0.0  norm   buff     H  \n6    down  2.0  norm   sick    S3  \n7      up  0.0  norm   buff     H  \n8    flat  1.0   rev   sick    S2  \n9    down  0.0   rev   sick    S1  \n10   flat  0.0   fix   buff     H  \n11   flat  0.0  norm   buff     H  \n12   flat  1.0   fix   sick    S2  \n13     up  0.0   rev   buff     H  \n14     up  0.0  norm   buff     H  \n15   flat  0.0  norm   buff     H  \n16     up  0.0  norm   buff     H  \n17   flat  0.0  norm   sick    S1  \n18     up  2.0   rev   sick    S3  \n19   flat  2.0   rev   sick    S4  \n20   flat  0.0  norm   buff     H  \n21     up  0.0  norm   buff     H  \n22   down  0.0  norm   buff     H  \n23     up  0.0  norm   buff     H  \n24   flat  0.0   rev   sick    S3  \n25     up  2.0  norm   buff     H  \n26     up  2.0   rev   sick    S2  \n27     up  0.0  norm   sick    S1  \n28   flat  0.0   rev   buff     H  \n29     up  0.0  norm   buff     H  \n..    ...  ...   ...    ...   ...  \n273    up  1.0  norm   buff     H  \n274    up  1.0  norm   buff     H  \n275  flat  3.0   rev   sick    S3  \n276    up  0.0   rev   buff     H  \n277    up  1.0   rev   sick    S2  \n278  flat  1.0   rev   sick    S1  \n279  flat  1.0  norm   sick    S1  \n280  flat  0.0  norm   buff     H  \n281  down  2.0   rev   sick    S3  \n282  flat  1.0   rev   sick    S3  \n283    up  0.0  norm   buff     H  \n284    up  0.0  norm   buff     H  \n285  flat  0.0   rev   buff     H  \n286    up  1.0   rev   buff     H  \n287  flat  1.0  norm   buff     H  \n288    up  2.0  norm   sick    S3  \n289    up  0.0  norm   buff     H  \n290    up  0.0  norm   buff     H  \n291  flat  1.0  norm   sick    S4  \n292  flat  0.0   fix   sick    S2  \n293    up  1.0   rev   buff     H  \n294    up  0.0   rev   buff     H  \n295    up  3.0  norm   sick    S4  \n296  flat  0.0  norm   buff     H  \n297  flat  0.0  norm   buff     H  \n298    up  2.0  norm   buff     H  \n299    up  0.0   rev   buff     H  \n300    up  3.0  norm   sick    S1  \n301    up  1.0  norm   buff     H  \n302    up  1.0  norm   buff     H  \n\n[303 rows x 15 columns]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 公共读的数据表项目\n",
    "# 集团内是pai_inner_project;\n",
    "# 集团外（公有云）是pai_online_project\n",
    "\n",
    "source_table_project = \"pai_inner_project\"\n",
    "\n",
    "dataset_table = \"odps://{}/tables/heart_disease_prediction\".format(source_table_project)\n",
    "\n",
    "odps_table = odps_client.get_table(\"heart_disease_prediction\", project=source_table_project)\n",
    "df = DataFrame(odps_table)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "- 将字符串数据转换为数值类型\n",
    "- run中传入的参数parameters dict，key表示的是对应的Manifest的inputs的name， value则表示需要输入的数据."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sql = \"select age, (case sex when 'male' then 1 else 0 end) as sex, (case cp when \" \\\n",
    "        \"'angina' then 0  when 'notang' then 1 else 2 end) as cp, trestbps, chol, (case\" \\\n",
    "        \" fbs when 'true' then 1 else 0 end) as fbs, (case restecg when 'norm' then 0 \" \\\n",
    "        \" when 'abn' then 1 else 2 end) as restecg, thalach, (case exang when 'true' then\" \\\n",
    "        \" 1 else 0 end) as exang, oldpeak, (case slop when 'up' then 0  when 'flat' then \" \\\n",
    "        \"1 else 2 end) as slop, ca, (case thal when 'norm' then 0  when 'fix' then 1\" \\\n",
    "        \" else 2 end) as thal, (case status  when 'sick' then 1 else 0 end) as\" \\\n",
    "        \" ifHealth from ${t1};\"\n",
    "\n",
    "# Extract and transform dataset using max_compute sql.\n",
    "sql_job = PipelineTemplate.get_by_identifier(\n",
    "    identifier=\"sql-xflow-maxCompute\", provider=ProviderAlibabaPAI, version=\"v1\").run(\n",
    "    job_name=\"sql-job\",\n",
    "    arguments={\n",
    "        \"execution\": xflow_execution,\n",
    "        \"inputArtifact1\": dataset_table,\n",
    "        \"sql\": sql,\n",
    "        \"outputTable\": gen_temp_table(),\n",
    "    })\n",
    "\n",
    "# because of outputs not ready after workflow finished.\n",
    "time.sleep(10)\n",
    "output_table_artifact = sql_job.get_outputs()[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sql_output_table = odps_client.get_table(output_table_artifact.value.table, output_table_artifact.value.project)\n",
    "DataFrame(sql_output_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Heart-disease-prediction的工作流包括以下\n",
    "\n",
    "- type_transform 完成数据类型转换，将部分列装换为doubel\n",
    "- normalize_job 完成数据归一化处理\n",
    "- split_job 切分数据为训练数据集和验证数据集\n",
    "- lr_job 使用训练数据集训练，获得一个offlineModel\n",
    "- transform_job 使用offlinemodel和验证数据集进行批量预测\n",
    "- evaluate_job 使用预测结果评估模型准确性\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pai.xflow.classifier import LogisticRegression\n",
    "# Transform value to Double\n",
    "type_transform_job = PipelineTemplate.get_by_identifier(\n",
    "    identifier=\"type-transform-xflow-maxCompute\",\n",
    "    provider=ProviderAlibabaPAI, version=\"v1\").run(\n",
    "    job_name=\"type-transform-job\",\n",
    "    arguments={\n",
    "        \"execution\": xflow_execution,\n",
    "        \"inputArtifact\": output_table_artifact,\n",
    "        \"cols_to_double\": 'sex,cp,fbs,restecg,exang,slop,thal,ifhealth,age,trestbps,chol,thalach,oldpeak,ca',\n",
    "        \"outputTable\": gen_temp_table(),\n",
    "    }\n",
    ")\n",
    "\n",
    "time.sleep(20)\n",
    "type_transform_result = type_transform_job.get_outputs()[0]\n",
    "\n",
    "# Normalize Feature\n",
    "normalize_job = PipelineTemplate.get_by_identifier(identifier=\"normalize-xflow-maxCompute\",\n",
    "                                            provider=ProviderAlibabaPAI, version=\"v1\").run(\n",
    "    job_name=\"normalize-job\",\n",
    "    arguments={\n",
    "        \"execution\": xflow_execution,\n",
    "        \"inputArtifact\": type_transform_result,\n",
    "        \"selectedColNames\": 'sex,cp,fbs,restecg,exang,slop,thal,ifhealth,age,trestbps,'\n",
    "                            'chol,thalach,oldpeak,ca',\n",
    "        \"lifecycle\": 1,\n",
    "        \"outputTableName\": gen_temp_table(),\n",
    "        \"outputParaTableName\": gen_temp_table(),\n",
    "    }\n",
    ")\n",
    "\n",
    "# because of outputs is not ready after run is succeeded.\n",
    "time.sleep(20)\n",
    "normalized_dataset = normalize_job.get_outputs()[0]\n",
    "\n",
    "split_job = PipelineTemplate.get_by_identifier(\n",
    "    identifier=\"split-xflow-maxCompute\",\n",
    "    provider=ProviderAlibabaPAI, version=\"v1\").run(\n",
    "    job_name=\"split-job\",\n",
    "    arguments={\n",
    "        \"inputArtifact\": normalized_dataset,\n",
    "        \"execution\": xflow_execution,\n",
    "        \"fraction\": 0.8,\n",
    "        \"output1TableName\": gen_temp_table(),\n",
    "        \"output2TableName\": gen_temp_table(),\n",
    "    }\n",
    ")\n",
    "\n",
    "time.sleep(20)\n",
    "split_output_1, split_output_2 = split_job.get_outputs()\n",
    "\n",
    "\n",
    "lr_job = LogisticRegression(\n",
    "    regularized_type=\"l2\", xflow_execution=xflow_execution,\n",
    "    pmml_gen=True, pmml_oss_bucket=oss_bucket_name,\n",
    "    pmml_oss_path=oss_path, pmml_oss_endpoint=oss_endpoint,\n",
    "    pmml_oss_rolearn=oss_rolearn,\n",
    ").fit(split_output_1,\n",
    "        wait=True,\n",
    "        feature_cols='sex,cp,fbs,restecg,exang,slop,thal,age,trestbps,chol,thalach,oldpeak,ca',\n",
    "        label_col=\"ifhealth\",\n",
    "        good_value=1,\n",
    "        model_name=\"test_health_prediction\")\n",
    "\n",
    "time.sleep(20)\n",
    "offlinemodel_artifact, pmml_output = lr_job.get_outputs()\n",
    "transform_job = PipelineTemplate.get_by_identifier(\n",
    "    identifier=\"prediction-xflow-maxCompute\",\n",
    "    provider=ProviderAlibabaPAI, version=\"v1\").run(\n",
    "    job_name=\"prediction-job\",\n",
    "    arguments={\n",
    "        \"inputModelArtifact\": offlinemodel_artifact,\n",
    "        \"inputDataSetArtifact\": split_output_2,\n",
    "        \"execution\": xflow_execution,\n",
    "        \"outputTableName\": gen_temp_table(),\n",
    "        \"featureColNames\": 'sex,cp,fbs,restecg,exang,slop,thal,age,trestbps,chol,thalach,oldpeak,ca',\n",
    "        \"appendColNames\": \"ifhealth\",\n",
    "    }\n",
    ")\n",
    "\n",
    "time.sleep(20)\n",
    "transform_result = transform_job.get_outputs()[0]\n",
    "\n",
    "evaluate_job = PipelineTemplate.get_by_identifier(\n",
    "    identifier=\"evaluate-xflow-maxCompute\",\n",
    "    provider=ProviderAlibabaPAI, version=\"v1\",\n",
    "    ).run(\n",
    "    job_name=\"evaluate-job\",\n",
    "    arguments={\n",
    "        \"execution\": xflow_execution,\n",
    "        \"inputArtifact\": transform_result,\n",
    "        \"outputDetailTableName\": gen_temp_table(),\n",
    "        \"outputELDetailTableName\": gen_temp_table(),\n",
    "        \"outputMetricTableName\": gen_temp_table(),\n",
    "        \"scoreColName\": \"prediction_score\",\n",
    "        \"labelColName\": \"ifhealth\",\n",
    "        \"coreNum\": 2,\n",
    "        \"memSizePerCore\": 512,\n",
    "    }\n",
    ")\n",
    "\n",
    "time.sleep(20)\n",
    "evaluate_result = evaluate_job.get_outputs()[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看训练效果评估数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluate_table = odps_client.get_table(evaluate_result.value.table, evaluate_result.value.project)\n",
    "DataFrame(evaluate_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上的case是一个step-by-step的任务，节点任务之间的串联是维护在具体的Python code中，不利于复杂Pipeline的分享复用，以及执行的优化。\n",
    "PAIFlow提供了将节点串联，构建为一个复合Pipeline的能力。\n",
    "\n",
    "## 复合Pipeline的构建\n",
    "\n",
    "\n",
    "- 使用PAI提供的Pipeline实现（包括，split, normalize, logisticregression, prediction, evaluate等）,构建出一个复合Pipeline工作定义。\n",
    "- 使用函数构建复合Pipeline：构建过程中出现的错误操作，不会污染notebook kernel的全局环境（除非对global变量进行写入），如果需要修改构建Pipeline的流程，例如修改参数名，减少参数，则只需要修改函数定义，重新运行函数获得新的Pipeline定义\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pai.pipeline.types import ArtifactDataType, ArtifactLocationType\n",
    "def create_heart_disease_pred_pl():\n",
    "    pmml_oss_bucket = PipelineParameter(\"pmml_oss_bucket\")\n",
    "    pmml_oss_rolearn = PipelineParameter(\"pmml_oss_rolearn\")\n",
    "    pmml_oss_path = PipelineParameter(\"pmml_oss_path\")\n",
    "    pmml_oss_endpoint = PipelineParameter(\"pmml_oss_endpoint\")\n",
    "    xflow_execution = PipelineParameter(\"xflow_execution\", dict)\n",
    "    dataset_input = PipelineArtifact(\"dataset-table\",\n",
    "                                        metadata=ArtifactMetadata(\n",
    "                                            data_type=ArtifactDataType.DataSet,\n",
    "                                            location_type=ArtifactLocationType.MaxComputeTable,\n",
    "                                        ),\n",
    "                                        required=True)\n",
    "\n",
    "    sql = \"select age, (case sex when 'male' then 1 else 0 end) as sex,(case cp when\" \\\n",
    "            \" 'angina' then 0  when 'notang' then 1 else 2 end) as cp, trestbps, chol,\" \\\n",
    "            \" (case fbs when 'true' then 1 else 0 end) as fbs, (case restecg when 'norm'\" \\\n",
    "            \" then 0  when 'abn' then 1 else 2 end) as restecg, thalach, (case exang when\" \\\n",
    "            \" 'true' then 1 else 0 end) as exang, oldpeak, (case slop when 'up' then 0  \" \\\n",
    "            \"when 'flat' then 1 else 2 end) as slop, ca, (case thal when 'norm' then 0 \" \\\n",
    "            \" when 'fix' then 1 else 2 end) as thal, (case status when 'sick' then 1 else \" \\\n",
    "            \"0 end) as ifHealth from ${t1};\"\n",
    "    sql_step = PipelineStep(\"sql-xflow-maxCompute\", name=\"sql-1\",\n",
    "                            provider=ProviderAlibabaPAI,\n",
    "                            version=\"v1\",\n",
    "                            inputs={\n",
    "                                \"inputArtifact1\": dataset_input,\n",
    "                                \"execution\": xflow_execution,\n",
    "                                \"sql\": sql,\n",
    "                                \"outputTable\": gen_temp_table(),\n",
    "                            })\n",
    "\n",
    "    type_transform_step = PipelineStep(\n",
    "        \"type-transform-xflow-maxCompute\",\n",
    "        name=\"type-transform-1\",\n",
    "        provider=ProviderAlibabaPAI, version=\"v1\",\n",
    "        inputs={\n",
    "            \"execution\": xflow_execution,\n",
    "            \"inputArtifact\": sql_step.outputs[\"outputArtifact\"],\n",
    "            \"cols_to_double\": 'sex,cp,fbs,restecg,exang,slop,thal,ifhealth,age,trestbps,'\n",
    "                                'chol,thalach,oldpeak,ca',\n",
    "            \"outputTable\": gen_temp_table(),\n",
    "\n",
    "        })\n",
    "\n",
    "    normalize_step = PipelineStep(\n",
    "        \"normalize-xflow-maxCompute\",\n",
    "        name=\"normalize-1\",\n",
    "        provider=ProviderAlibabaPAI,\n",
    "        version=\"v1\", inputs={\n",
    "            \"execution\": xflow_execution,\n",
    "            \"inputArtifact\": type_transform_step.outputs[\"outputArtifact\"],\n",
    "            \"selectedColNames\": 'sex,cp,fbs,restecg,exang,slop,thal,ifhealth,age,trestbps,'\n",
    "                                'chol,thalach,oldpeak,ca',\n",
    "            \"lifecycle\": 1,\n",
    "            \"outputTableName\": gen_temp_table(),\n",
    "            \"outputParaTableName\": gen_temp_table(),\n",
    "\n",
    "        })\n",
    "\n",
    "    split_step = PipelineStep(\n",
    "        identifier=\"split-xflow-maxCompute\",\n",
    "        name='split-1',\n",
    "        provider=ProviderAlibabaPAI, version=\"v1\", inputs={\n",
    "            \"inputArtifact\": normalize_step.outputs[\"outputArtifact\"],\n",
    "            \"execution\": xflow_execution,\n",
    "            \"fraction\": 0.8,\n",
    "            \"output1TableName\": gen_temp_table(),\n",
    "            \"output2TableName\": gen_temp_table(),\n",
    "\n",
    "        }\n",
    "    )\n",
    "\n",
    "    model_name = 'test_health_prediction_by_pipeline_%s' % (random.randint(0, 999999))\n",
    "\n",
    "    lr_step = PipelineStep(\n",
    "        identifier=\"logisticregression-binary-xflow-maxCompute\",\n",
    "        name=\"logisticregression-1\",\n",
    "        provider=ProviderAlibabaPAI, version=\"v1\", inputs={\n",
    "            \"inputArtifact\": split_step.outputs[\"outputArtifact1\"],\n",
    "            \"execution\": xflow_execution,\n",
    "            \"generatePmml\": True,\n",
    "            \"endpoint\": pmml_oss_endpoint,\n",
    "            \"bucket\": pmml_oss_bucket,\n",
    "            \"path\": pmml_oss_path,\n",
    "            \"rolearn\": pmml_oss_rolearn,\n",
    "            # \"regulizedType\": \"l2\",\n",
    "            \"modelName\": model_name,\n",
    "            \"goodValue\": 1,\n",
    "            \"featureColNames\": \"sex,cp,fbs,restecg,exang,slop,thal,age,trestbps,chol,thalach,oldpeak,ca\",\n",
    "            \"labelColName\": \"ifhealth\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    offline_model_pred_step = PipelineStep(\n",
    "        identifier=\"prediction-xflow-maxCompute\",\n",
    "        name=\"offlinemodel-pred\",\n",
    "        provider=ProviderAlibabaPAI, version=\"v1\", inputs={\n",
    "            \"inputModelArtifact\": lr_step.outputs[\"outputArtifact\"],\n",
    "            \"inputDataSetArtifact\": split_step.outputs[\"outputArtifact2\"],\n",
    "            \"execution\": xflow_execution,\n",
    "            \"outputTableName\": gen_temp_table(),\n",
    "            \"featureColNames\": 'sex,cp,fbs,restecg,exang,slop,thal,age,trestbps,chol,thalach,oldpeak,ca',\n",
    "            \"appendColNames\": \"ifhealth\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    evaluate_step = PipelineStep(\n",
    "        identifier=\"evaluate-xflow-maxCompute\",\n",
    "        name=\"evaluate-1\",\n",
    "        provider=ProviderAlibabaPAI, version=\"v1\",\n",
    "        inputs={\n",
    "            \"execution\": xflow_execution,\n",
    "            \"inputArtifact\": offline_model_pred_step.outputs[\"outputArtifact\"],\n",
    "            \"outputDetailTableName\": gen_temp_table(),\n",
    "            \"outputELDetailTableName\": gen_temp_table(),\n",
    "            \"outputMetricTableName\": gen_temp_table(),\n",
    "            \"scoreColName\": \"prediction_score\",\n",
    "            \"labelColName\": \"ifhealth\",\n",
    "            \"coreNum\": 2,\n",
    "            \"memSizePerCore\": 512,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    p = Pipeline(\n",
    "        steps=[evaluate_step, offline_model_pred_step],\n",
    "        outputs={\"pmmlModel\": lr_step.outputs[\"outputArtifact\"],\n",
    "                    \"evaluateResult\": evaluate_step.outputs[\"outputMetricsArtifact\"]\n",
    "                    }\n",
    "    )\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建Pipeline\n",
    "- 可以使用`pipeline.dot()`命令查看Pipeline的运行拓扑图(需要安装graphviz)\n",
    "- 可以通过p.to_dict()方法获得对应的Pipeline Manifest的定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "p = create_heart_disease_pred_pl()\n",
    "print(yaml.dump(p.to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "p.dot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行Pipeline\n",
    "- 指定输入参数，运行Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "run_instance = p.run(job_name=\"heart-disease-pipeline-job\", arguments={\n",
    "    \"dataset-table\": dataset_table,\n",
    "    \"xflow_execution\": xflow_execution,\n",
    "    \"pmml_oss_endpoint\": oss_endpoint,\n",
    "    \"pmml_oss_bucket\": oss_bucket_name,\n",
    "    \"pmml_oss_path\": oss_path,\n",
    "    \"pmml_oss_rolearn\": oss_rolearn,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "run_instance.get_outputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将Pipeline推送到服务端保存，进行复用\n",
    "- 保存的Pipeline 可以作为其他Pipeline的节点进行复用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "p.save(identifier=\"heart-disease-prediction-pl\", version=\"v%s\"%int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "save_pipeline = PipelineTemplate.get(p.pipeline_id).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_pipeline.dot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "saved_pipeline = PipelineTemplate.get(p.pipeline_id)\n",
    "saved_pipeline.run(job_name=\"saved-pl-heart-disease-job\", arguments={\n",
    "    \"dataset-table\": dataset_table,\n",
    "    \"xflow_execution\": xflow_execution,\n",
    "    \"pmml_oss_endpoint\": oss_endpoint,\n",
    "    \"pmml_oss_bucket\": oss_bucket_name,\n",
    "    \"pmml_oss_path\": oss_path,\n",
    "    \"pmml_oss_rolearn\": oss_rolearn,\n",
    "})"
   ]
  }
 ]
}