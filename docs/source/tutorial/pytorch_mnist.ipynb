{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "source": [
    "# 使用 PAI Python SDK 训练和部署PyTorch模型\n",
    "\n",
    "[PyTorch](https://pytorch.org/) 是当前主流的深度学习框架, 它提供了高度的灵活性和速度，使得开发者能够快速的构建和训练深度学习模型。PyTorch使用动态图技术，可以更好的实现复杂的计算流程，支持GPU加速，也可以方便的与其他Python库进行集成。当前示例中，我们将使用 PAI Python SDK，在 PAI 完成一个 PyTorch 模型的训练，然后使用训练获得的模型部署推理服务。主要流程包括:\n",
    "\n",
    "\n",
    "1. 准备工作：\n",
    "\n",
    "安装 PAI Python SDK，并完成 SDK 配置.\n",
    "\n",
    "2. 准备训练脚本\n",
    "\n",
    "我们基于 PyTorch 示例仓库中的 MNIST 训练脚本作为模版，演示如何编写一个符合要求的训练脚本。\n",
    "\n",
    "\n",
    "3. 提交训练作业\n",
    "\n",
    "使用 PAI Python SDK提供的 Estimator API，创建一个训练作业，提交到云上执行。\n",
    "\n",
    "4. 部署模型\n",
    "\n",
    "将以上训练作业输出的模型，分别使用 Processor 模式和镜像部署模式，部署到 PAI-EAS，创建在线推理服务。\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step1: 准备工作\n",
    "\n",
    "我们需要首先安装 PAI Python SDK 以运行本示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "!python -m pip install alipai -f https://pai-sdk.oss-cn-shanghai.aliyuncs.com/repo/index.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "SDK 需要配置访问阿里云服务需要的 AccessKey，以及当前使用的工作空间和OSS Bucket。在 PAI SDK 安装之后，通过在 **命令行终端** 中执行以下命令，按照引导配置密钥，工作空间等信息。\n",
    "\n",
    "\n",
    "```shell\n",
    "\n",
    "# 以下命令，请在 命令行终端 中执行.\n",
    "\n",
    "python -m pai.toolkit.config\n",
    "\n",
    "```\n",
    "\n",
    "我们可以通过以下代码验证当前的配置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pai\n",
    "from pai.session import get_default_session\n",
    "\n",
    "print(pai.__version__)\n",
    "\n",
    "sess = get_default_session()\n",
    "\n",
    "assert sess.workspace_name is not None\n",
    "print(sess.workspace_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step2: 准备训练脚本\n",
    "\n",
    "当前示例使用 MNIST 数据集训练一个图片分类模型，这里我们以 PyTorch 官方提供的 [MNIST 示例](https://github.com/pytorch/examples/blob/main/mnist/main.py) 为基础，修改了模型保存部分的逻辑，作为训练脚本。\n",
    "\n",
    "修改代码如下，训练脚本需要将输出模型保存到 `/ml/output/model/` 路径下。\n",
    "\n",
    "```diff\n",
    "\n",
    "-     if args.save_model:\n",
    "-         torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
    "\n",
    "+     # 保存模型\n",
    "+     save_model(model)\n",
    "+\n",
    "+\n",
    "+ def save_model(model):\n",
    "+     \"\"\"将模型转为TorchScript，保存到指定路径.\"\"\"\n",
    "+\n",
    "+     output_model_path = \"/ml/output/model/\"\n",
    "+     os.makedirs(output_model_path, exist_ok=True)\n",
    "+\n",
    "+     m = torch.jit.script(model)\n",
    "+     m.save(os.path.join(output_model_path, \"mnist_cnn.pt\"))\n",
    "\n",
    "```\n",
    "\n",
    "PAI 提供的预置 [PyTorch Processor](https://help.aliyun.com/document_detail/470458.html) 在创建服务时，要求输入的模型是 [TorchScript 格式](https://pytorch.org/docs/stable/jit.html) 。在当前示例中，我们将模型导出为 `TorchScript格式` ，然后使用 `PyTorch Processor` 创建推理服务。\n",
    "\n",
    "用户可以根据需求使用 [torch.save](https://pytorch.org/tutorials/beginner/saving_loading_models.html) 直接保存模型，导出为 [ONNX格式](https://pytorch.org/docs/stable/onnx.html)等方式保存模型，脚本需要将模型写到 `/ml/output/model/` 目录下，PAI才能够将用户的模型持久化保存到 OSS。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "完整的作业脚本如下。在 Notebook 中执行时，`%%writefile` 指令会将单元格内的代码保存到本地。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!mkdir -p train_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%writefile train_src/train.py\n",
    "\n",
    "# source: https://github.com/pytorch/examples/blob/main/mnist/main.py\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(data),\n",
    "                    len(train_loader.dataset),\n",
    "                    100.0 * batch_idx / len(train_loader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "            if args.dry_run:\n",
    "                break\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(\n",
    "                output, target, reduction=\"sum\"\n",
    "            ).item()  # sum up batch loss\n",
    "            pred = output.argmax(\n",
    "                dim=1, keepdim=True\n",
    "            )  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
    "            test_loss,\n",
    "            correct,\n",
    "            len(test_loader.dataset),\n",
    "            100.0 * correct / len(test_loader.dataset),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Training settings\n",
    "    parser = argparse.ArgumentParser(description=\"PyTorch MNIST Example\")\n",
    "    parser.add_argument(\n",
    "        \"--batch-size\",\n",
    "        type=int,\n",
    "        default=64,\n",
    "        metavar=\"N\",\n",
    "        help=\"input batch size for training (default: 64)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--test-batch-size\",\n",
    "        type=int,\n",
    "        default=1000,\n",
    "        metavar=\"N\",\n",
    "        help=\"input batch size for testing (default: 1000)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--epochs\",\n",
    "        type=int,\n",
    "        default=14,\n",
    "        metavar=\"N\",\n",
    "        help=\"number of epochs to train (default: 14)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr\",\n",
    "        type=float,\n",
    "        default=1.0,\n",
    "        metavar=\"LR\",\n",
    "        help=\"learning rate (default: 1.0)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gamma\",\n",
    "        type=float,\n",
    "        default=0.7,\n",
    "        metavar=\"M\",\n",
    "        help=\"Learning rate step gamma (default: 0.7)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--no-cuda\", action=\"store_true\", default=False, help=\"disables CUDA training\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dry-run\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"quickly check a single pass\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--seed\", type=int, default=1, metavar=\"S\", help=\"random seed (default: 1)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--log-interval\",\n",
    "        type=int,\n",
    "        default=10,\n",
    "        metavar=\"N\",\n",
    "        help=\"how many batches to wait before logging training status\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--save-model\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"For Saving the current Model\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    train_kwargs = {\"batch_size\": args.batch_size}\n",
    "    test_kwargs = {\"batch_size\": args.test_batch_size}\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {\"num_workers\": 1, \"pin_memory\": True, \"shuffle\": True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    )\n",
    "    dataset1 = datasets.MNIST(\"../data\", train=True, download=True, transform=transform)\n",
    "    dataset2 = datasets.MNIST(\"../data\", train=False, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "    # 保存模型\n",
    "    save_model(model)\n",
    "\n",
    "\n",
    "def save_model(model):\n",
    "    \"\"\"将模型转为TorchScript，保存到指定路径.\"\"\"\n",
    "\n",
    "    output_model_path = \"/ml/output/model/\"\n",
    "    os.makedirs(output_model_path, exist_ok=True)\n",
    "\n",
    "    m = torch.jit.script(model)\n",
    "    m.save(os.path.join(output_model_path, \"mnist_cnn.pt\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PAI 提供了常见的机器学习框架的基础镜像，支持用户提交训练作业。通过 `pai.image.list_images` 可以列出PAI提供的公共镜像\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrameworkVersion\tAcceleratorType\tImageURI\n",
      "1.12PAI\tgpu\tregistry.cn-hangzhou.aliyuncs.com/pai-dlc/pytorch-training:1.12PAI-gpu-py38-cu113-ubuntu20.04\n",
      "1.8PAI\tgpu\tregistry.cn-hangzhou.aliyuncs.com/pai-dlc/pytorch-training:1.8PAI-gpu-py36-cu101-ubuntu18.04\n",
      "1.7PAI\tgpu\tregistry.cn-hangzhou.aliyuncs.com/pai-dlc/pytorch-training:1.7PAI-gpu-py36-cu101-ubuntu18.04\n"
     ]
    }
   ],
   "source": [
    "from pai.image import list_images, ImageScope, retrieve\n",
    "\n",
    "print(\"FrameworkVersion\\tAcceleratorType\\tImageURI\")\n",
    "for image in list_images(framework_name=\"PyTorch\", image_scope=ImageScope.TRAINING):\n",
    "    print(\n",
    "        \"{}\\t{}\\t{}\".format(\n",
    "            image.framework_version, image.accelerator_type, image.image_uri\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在当前示例中，我们使用PAI提供的`1.8PAI`版本的GPU镜像提交训练作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registry.cn-hangzhou.aliyuncs.com/pai-dlc/pytorch-training:1.8PAI-gpu-py36-cu101-ubuntu18.04\n"
     ]
    }
   ],
   "source": [
    "image_uri = retrieve(\n",
    "    \"PyTorch\", framework_version=\"1.8PAI\", accelerator_type=\"GPU\"\n",
    ").image_uri\n",
    "print(image_uri)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step3: 提交训练作业\n",
    "\n",
    "`Estimator` 支持用户将本地的训练脚本，提交到 PAI，使用指定的作业镜像执行，使用云上的资源执行训练作业。\n",
    "\n",
    "- 用户通过 `entry_point` 和  `source_dir` 指定训练脚本:\n",
    "\n",
    "`source_dir` 目录是本地执行脚本所在的目录，对应的目录会被打包上传到用户的OSS Bucket，在训练作业执行前，加载到作业的运行环境中。 `entry_point` 是训练作业的启动脚本，支持使用 Python 或是 Shell 文件。\n",
    "\n",
    "对于 Python 脚本，训练作业会以通过以下默认启动:\n",
    "\n",
    "```shell\n",
    "\n",
    "python {entry_point} --{hyperparameters_in_arguments}\n",
    "\n",
    "```\n",
    "\n",
    "对于 Shell 脚本，则会使用以下方式运行对应的脚本\n",
    "\n",
    "```shell\n",
    "\n",
    "sh -s {entry_point} --{hyperparameters_in_arguments}\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "- 通过 `image_uri` 指定作业的训练镜像:\n",
    "\n",
    "- 通过 `hyperparameters` 传递的作业使用的超参:\n",
    "\n",
    "超参会通过命令行 arguments 的方式传递给到训练脚本。 例如以下示例中，对应的训练脚本的启动命令为:\n",
    "\n",
    "```shell\n",
    "\n",
    "python train.py --epochs 5 --batch-size 256\n",
    "\n",
    "```\n",
    "\n",
    "- 使用 `metric_definitions` 指定需要采集的Metric:\n",
    "\n",
    "PAI 的训练服务从训练作业输出日志中，以正则的方式捕获用户指定的Metrics信息。用户可以通过作业详情页查看输出日志。\n",
    "\n",
    "- 使用 `instance_type` 指定作业使用的机器实例类型:\n",
    "\n",
    "\n",
    "对于提交训练作业的更加详细的介绍，请查看 [文档:提交训练作业](https://pai-sdk.oss-cn-shanghai.aliyuncs.com/pai/doc/latest/user-guide/estimator.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pai.estimator import Estimator\n",
    "from pai.image import retrieve\n",
    "\n",
    "\n",
    "est = Estimator(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"./train_src/\",\n",
    "    image_uri=image_uri,\n",
    "    instance_type=\"ecs.gn6i-c4g1.xlarge\",  # 4vCPU 15GB 1*NVIDIA T4\n",
    "    hyperparameters={\n",
    "        \"epochs\": 5,\n",
    "        \"batch-size\": 64 * 4,\n",
    "    },\n",
    "    metric_definitions=[\n",
    "        {\n",
    "            \"Name\": \"loss\",\n",
    "            \"Regex\": r\".*loss=\" r\"([-+]?[0-9]*.?[0-9]+(?:[eE][-+]?[0-9]+)?).*\",\n",
    "        },\n",
    "    ],\n",
    "    base_job_name=\"pytorch_mnist\",\n",
    ")\n",
    "est.fit()\n",
    "\n",
    "# 训练作业产出的模型路径\n",
    "print(\"TrainingJob output model data:\")\n",
    "print(est.model_data())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`est.fit` 方法将用户的训练作业提交到 PAI 上执行。任务提交之后，`.fit` 方法会打印作业的URL，以及作业的执行日志，默认等待到作业执行结束才会退出。\n",
    "\n",
    "当用户需要直接使用 OSS 上的数据，或是 NAS 盘上的数据，可以通过 `.fits` 方法的 `inputs` 参数传递。\n",
    "\n",
    "```python\n",
    "\n",
    "est.fit(\n",
    "\tinputs={\n",
    "\t\t# 数据会被挂载到 /ml/input/data/train/ 路径下\n",
    "\t\t\"train\": \"oss://{YourOssBucket}/path/to/train/data\",\t\n",
    "\t\t# 数据会被挂载到 /ml/input/data/test/ 路径下\n",
    "\t\t\"test\": \"nas://{YourOssBucket}/path/to/test/data\",\t\n",
    "\t}\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "通过 `inputs` 传递数据存储路径会被挂载到 `/ml/input/data/{Name}` 目录下，用户的训练脚本可以通过读取对应的目录获得输入的数据。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step4: 部署推理服务\n",
    "\n",
    "通过 `Estimator.model_data()`，我们可以拿到训练作业产出模型的OSS路径。下面的流程中我们将训练产出的模型部署到 PAI 创建在线推理服务。\n",
    "\n",
    "部署推理服务的主要流程包括：\n",
    "\n",
    "- 通过 `InferenceSpec` 描述如何使用模型构建推理服务。\n",
    "\n",
    "用户可以选择使用 Processor 模式，或是自定义镜像的模式进行模型部署。以下示例中将使用两种方式分别部署获得的 PyTorch 模型。\n",
    "\n",
    "- 通过 `Model.deploy` 方法，配置服务的使用资源，服务名称，等信息，创建推理服务。\n",
    "\n",
    "对于部署推理服务的详细介绍，可以见: [文档:部署推理服务](https://pai-sdk.oss-cn-shanghai.aliyuncs.com/pai/doc/latest/user-guide/model.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processor 模式部署\n",
    "\n",
    "[Processor](https://help.aliyun.com/document_detail/111029.html) 是 PAI 对于推理服务程序包的抽象描述，他负责加载模型，启动模型推理服务。模型推理服务会暴露 API 支持用户进行调用。\n",
    "\n",
    "对于 PyTorch ，PAI提供了预置的 [PyTorch Processor](https://help.aliyun.com/document_detail/470458.html) ，用户可以方便得将获得的 `TorchScript` 格式的模型部署到 PAI，创建推理服务。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pai.model import Model, InferenceSpec\n",
    "from pai.predictor import Predictor\n",
    "from pai.common.utils import random_str\n",
    "\n",
    "\n",
    "m = Model(\n",
    "    model_data=est.model_data(),\n",
    "    # 使用PAI提供的PyTorch Processor\n",
    "    inference_spec=InferenceSpec(processor=\"pytorch_cpu_1.10\"),\n",
    ")\n",
    "\n",
    "p: Predictor = m.deploy(\n",
    "    service_name=\"tutorial_pt_mnist_proc_{}\".format(random_str(6)),\n",
    "    instance_type=\"ecs.c6.xlarge\",\n",
    ")\n",
    "\n",
    "print(p.service_name)\n",
    "print(p.service_status)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`Model.deploy` 返回的 `Predictor` 对象指向新创建的推理服务，可以通过 `Predictor.predict` 方法发送预测请求给到服务，拿到预测结果。\n",
    "\n",
    "\n",
    "导出的TorchScritp模型要求输入为 Float32，数据格式格式的形状为 (BatchSize, Channel, Weight, Height)。我们使用 numpy 构建了一个测试样本数据，发送给到推理服务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dummy_input = np.random.rand(2, 1, 28, 28).astype(np.float32)\n",
    "\n",
    "# np.random.rand(1, 1, 28, 28).dtype\n",
    "res = p.predict(dummy_input)\n",
    "print(res)\n",
    "\n",
    "print(np.argmax(res, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "在测试完成之后，删除相关的服务，释放资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p.delete_service()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 镜像部署\n",
    "\n",
    "Processor 模式拉起的推理服务性能较高，适合于对于性能较为敏感的场景。对于一些需要灵活自定义的场景，例如用户模型使用了一些第三方的依赖，或是推理服务需要有前处理和后处理，可以通过镜像部署的方式的方式实现。 SDK 提供了便利方法 `InferenceSpec.from_serving_script` ，支持用户使用本地脚本配合 PAI 提供的基础镜像的方式创建推理服务。\n",
    "\n",
    "\n",
    "以下是使用 Flask 编写的模型服务：在接受用户的HTTP请求，将数据图片进行预处理，然后使用模型进行推理，然后返回预测结果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p infer_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile infer_src/run.py\n",
    "\n",
    "\n",
    "import json\n",
    "from flask import Flask, request\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "app = Flask(__name__)\n",
    "# 用户指定模型，默认会被加载到当前路径下。 \n",
    "MODEL_PATH = \"/eas/workspace/model/\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.jit.load(os.path.join(MODEL_PATH, \"mnist_cnn.pt\")).to(device)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "\n",
    "\n",
    "@app.route(\"/\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    # 预处理图片数据\n",
    "    im = Image.open(io.BytesIO(request.data))\n",
    "    input_tensor = transform(im).to(device)\n",
    "\n",
    "    input_tensor.unsqueeze_(0)\n",
    "\n",
    "    # 使用模型进行推理\n",
    "    output_tensor = model(input_tensor)\n",
    "    pred_res =output_tensor.detach().cpu().numpy()[0] \n",
    "\n",
    "    return json.dumps(pred_res.tolist())\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"0.0.0.0\", port=int(os.environ.get(\"LISTENING_PORT\", 8000)))\n",
    "\n",
    "# 使用测试数据集发送"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "通过 `InferenceSpec.from_serving_script`，我们基于本地脚本和 PAI 提供的 PyTorch 镜像创建了一个InferenceSpec对象。\n",
    "\n",
    "- 用户指定的本地脚本目录 `source_dir` 的会被上传到OSS，然后挂载到容器作业中供用户推理程序使用。\n",
    "  \n",
    "- 推理服务的容器内会通过 ``python {{entry_point}}`` 的方式启动用户的推理程序。当前示例下，也就是以上的Flask 程序。\n",
    "\n",
    "- PAI 提供了基础的推理镜像支持用户使用，用户可以通过 `pai.image.retrieve` 方法，指定参数 `image_scope=\"inference\"` 获取指定框架在推理场景使用的镜像。\n",
    "\n",
    "- 用户的代码或是模型的依赖，可以通过 `requirements` 参数指定，相应的依赖会在服务程序启动前被安装到环境中。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pai.model import InferenceSpec\n",
    "from pai.image import retrieve, ImageScope\n",
    "\n",
    "torch_image_uri = retrieve(\n",
    "    framework_name=\"pytorch\", framework_version=\"1.8PAI\", accelerator_type=\"GPU\"\n",
    ").image_uri\n",
    "\n",
    "inf_spec = InferenceSpec.from_serving_script(\n",
    "    entry_point=\"run.py\",\n",
    "    source_dir=\"./infer_src/\",\n",
    "    image_uri=torch_image_uri,\n",
    "    requirements=[\"flask==2.0.0\"],\n",
    ")\n",
    "print(inf_spec.to_dict())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用训练作业输出的模型，以及以上的 InferenceSpec，我们将通过 Model.deploy API部署一个在线推理服务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pai.model import Model\n",
    "from pai.common.utils import random_str\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "m = Model(\n",
    "    model_data=est.model_data(),\n",
    "    inference_spec=inf_spec,\n",
    ")\n",
    "\n",
    "container_serving_predictor = m.deploy(\n",
    "    service_name=\"torch_mnist_script_container_{}\".format(random_str(6)),\n",
    "    instance_type=\"ecs.gn6i-c4g1.xlarge\",  # 4vCPU 15GB 1*NVIDIA T4\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "我们准备一张 MNIST 测试图片，用于发送给到推理服务。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "keep_output"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABvklEQVR4nF2SO2tUURSFv73PPufMMzGG+EALhZhoaxBs7EWwCoiNhfgbLERrQSwshfwA7SyTIIJgJVgpBBEhEZuQQsIgE/XeubMtZu4wk9UuztrrcWAMEwACGQQSs9CUFARyApuhogKICSFgzZFaTZaoigwHolSo2GD6pYTRUTOoZbUmvXJodhoDMUJDwqyflAGYA6vNyrSntfXbq38e95a3PwQtAVSwjELm/v6hb30ZlL6Rwlg2gSLQvb7vn9bS3JuhP6EzFmsIEoF77ptB853Sd05oitRJrcXp5/5zY9Gwb95fR8dlKiCZh799K2Hdm4e7T1s6ZTIiZ/aq11hc2nF/Hw0h1wEj4awX50892vS/v/q3YIl5JrK0WgfeL32wu+c/WJyZKsLcaq/4+uziuXfFi0QkyuhsAIWwQIb5G+4PkPZk6gQSgNCE7mXvrUAgjQcx0Fh7Pzn0DgJGBLAKvHINPgj56GpRNigKnBLAXHDHpaI6YjkXw3/lZCrFAajoBvhcdFMJUk11FEzHE3/3a22yYFPsKK0m7vrHS3Qjx2EE48rLg7dEYvsYqSKCXnjVX2lrg9kPJpOiAVnIAP8B0Kx+GvoyGWQAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "!pip install -q pillow\n",
    "\n",
    "\n",
    "import base64\n",
    "from PIL import Image\n",
    "from IPython import display\n",
    "import io\n",
    "\n",
    "\n",
    "# raw_data是一张MNIST图片\n",
    "raw_data = base64.b64decode(b\"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+rVhpmoarP5GnWNzeTYz5dvE0jfkoJovNMv8ATmK3tjc2zByhE8TIQw6jkdR6VVq9oumPrWuWGlxyLG95cRwK7dFLMFyfzr3aXwp4ltAfB3gWwudI01JNuoa7eZhku5AMHafvFOw2Dn6ZJ4z4yeLk1HUbXwrZSSy2Oh5heeaQu88wG1mLHk4wR9c+1eXUqsVYMpIIOQR2r1D4QazqOs/FnSG1fVLi9ZI5vL+2TNKc+U2ApYnB7/hXml5LLNfXEsxLSvIzOSMEsTk1DRVnT7+60vULe/spmhureQSRSL1Vh0NWNd1mXX9ZuNUuLe2gmuCGkS2QohbABbBJwTjJ9yelZ1f/2Q==\")\n",
    "\n",
    "im = Image.open(io.BytesIO(raw_data))\n",
    "\n",
    "display.display(im)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推理服务使用 HTTP 请求体内的数据作为输入的图片，SDK 的 `raw_predict` 方法接受 bytes 数据类型的请求，通过 POST 方法，在请求内带上用户推理数据，发送给到推理服务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "resp = container_serving_predictor.raw_predict(data=raw_data)\n",
    "\n",
    "print(json.loads(resp))\n",
    "\n",
    "print(np.argmax(json.loads(resp)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试完成之后删除服务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_serving_predictor.delete_service()"
   ]
  }
 ],
 "metadata": {
  "execution": {
   "timeout": 1800
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
